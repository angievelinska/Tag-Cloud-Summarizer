

In this section you find hints on how to fix problems with CoreMedia Analytics. In the first part, some common error situation are described together with typical causes and solutions. In the second part, a set of debugging procedures is presented that allows you to locate the source of an error by actively performing experiments with the system.

Typical Errors

Each subsection contains as its headline a concise problem description. Afterwards, a list of potential problems and recommended checks is presented.

Dashboard Shows Errors for all Reports

Check whether the database connection is configured correctly in analytics/WEB-INF/custom/analytics/analyticsdashboard.properties.
Check whether the database driver jar is placed in analytics/WEB-INF/lib.
Check whether the Workflow Server that hosts the Data Aggregator has completed its startup sequence successfully.
If you have added custom reports to the dashboard, verify whether an out-of-the-box dashboard works correctly.
Check whether logs/analyticsdashboard.log contains any error messages.

In-Site Analytics does not Show Overlays

Ensure that sessions are enabled in the In-Site Analytics web application.
Check the web application log for error messages.
Check whether the JSPs that contain the Analytics taglib are actually used by including markers in the generated page.
Check the property overlay.default.visible in the file WEB-INF/spring/analytics/overlay.properties.

In-Site Analytics Shows Errors for all Overlays

Check whether the database is correctly configured in the file WEB-INF/spring/analytics/overlay.properties.
Check whether the database driver jar is placed in WEB-INF/lib.
Check the web application log for error messages.

Page Views Appear Nowhere

This case assumes that both the Analytics Dashboard and In-Site Analytics do not reports errors, but do not show any page views, either.

Check whether all tracking CAEs are configured as log providers in the file properties/corem/workflowserver.properties in the Data Aggregator installation.
Go through the procedure Determine the Data Aggregator Status described later in this section.
Go through the procedure Analyze Processing of Page Views described later in this section.

Page Views Appear in the Dashboard Only

Go through the procedure Analyze Processing of Page Views described later in this section.
During the analysis, check whether any page IDs and particularly page object ID differ from the IDs of the objects involved in rendering.
When only the link overlays are at fault, but the page overlay is correct, consider any object sustitution that might happen during rendering. In section you can find some hints on choosing an appropriate tracking method.

Page Views Appear in In-Site Analytics Only

Check whether enough time has elapsed since you made the page views. You must wait until the next full hour, then wait for the session timeout, and then wait until the Data Aggregator has started and completed a new iteration.
Check whether you can select a different site in the detail reports and find the page views there.
Go through the procedure Determine the Data Aggregator Status described later in this section. Pay particular attention to failed log providers as these might cause a delay of the aggregation for the dashboard, but not In-Site Analytics. Failed search log imports, too, might have this effect.

Repository Statistics are Empty

Check whether the Object Analyzer has completed its initial run and is idle.
Because repository statistics are generated at midnight, you will have to wait until the next day for new values, even if the Object Analyzer has run. 
Check whether the correct time zone is configure in the workflowserver.properties. Otherwise, midnight might no happen at the time when you expect it.

Repository Statistics or Display Names are Wrong

Check whether the data from the Object Analyzer is correct. To this end, issue statements like

SELECT COUNT(*) FROM CurrentObjectState

or

SELECT * FROM CurrentObjectState
WHERE objectid='contentbean:1'

and check whether the generated values look plausible.

When you correct the algorithm to compute the category or the display name for a content item, make sure to rerun the Object Analyzer with the setting

proactiveengine.clear=false

in the file proactiveengine.properties. Remember that the repository statistics will only be regenerated at next midnight.

Go through the procedure Analyze the Object Analyzer described later in this section.

Sessions are Always One Page View Long

If you have added a custom SessionExtractor, check the implementation. Going through the procedure Analyze Processing of Page Views described later in this section, pay attention to the session IDs that are written.
If you use the default SessionExtractor, check whether session cookies or session-specific URLs get lost through proxies or link rewriting.

Many Sessions are Merged into One

If you have added a custom SessionExtractor, check the implementation. Going through the procedure Analyze Processing of Page Views described later in this section, pay attention to the session IDs that are written.
If you use the default SessionExtractor, check whether sessions are disabled in the JSPs. In that case, a synthetic session ID is generated from requesting IP and browser. If the requesting IP cannot be determined any longer because of intermediate proxies, this heuristic might be too weak.

Debugging Procedures

In some cases, the source of a problem might not be immediately obvious. In that case, the following debugging procedures might help you.

Determine the Data Aggregator Status

Check whether the Data Aggregator is running correctly by searching for error messages in the file var/logs/workflowserver.log in the Data Aggregator installation.
Check whether the Workflow Server is running correctly by invoking

cm workflowserver status

on the command line.

Check whether the Data Aggregator is running correctly by invoking 

cm dataaggregator -u admin status



and analyzing its output.

The Data Aggregator should be running. If it isn't, start it.
There should be no failed log providers. If there are, inspect the log provider configuration and check whether the CAEs are all running correctly.
There should be no escalated tasks. If there are, restart the Data Aggregator. If that does not help, contact the CoreMedia support.
The variable iterationStart should be set to a value close to the current time. When the iteration duration is set to 5 minutes (the default of workflow.server.managers.aggregator.loop.duration), the iteration start should be no longer than 5 minutes in the future and not much longer than 5 minutes in the past.
The variable consolidationEnd should be set to a value in the past, but not much longer than the iteration duration.
The variable closeSessionsBefore should be set to the value of consolidationEnd minus the session timeout (the default being 30 minutes as configured by workflow.server.managers.aggregator.loop.duration).
The variable aggregatePermanentlyBefore should be the full minute before or at closeSessionsBefore unless you have changed the In-Site Analytics time granularity from its default of 60 seconds.

If the given dates are too far in the future, consider problems with the system clock, possibly during earlier runs of the Data Aggregator. If the given dates are too far in the past, check whether Analytics is running under overload (typically with 100% CPU and high I/O traffic on the database machine). Also check for communication problems between the system components.

Check whether the aggregation limit is correctly written to the database by issuing the SQL command

SELECT * FROM PermanentlyAggregatedBefore

for a single-valued output. This value should be similar to the setting of the workflow variable aggregatePermanentlyBefore, with a few minutes delay.

Check the Workflow Server log for entries of the form

imported 3 lines with column type distribution [15239*6, 20672*11]



The previous line would indicate that there are 15239 events of type 6 and 20672 events of type 11. The important event types in this context are:

6: JavaScript-based callbacks transporting hints that a transion between one page and another might have happened,
10: views of page parts marked by <analytics:namecontext logView="true"> or <analytics:objectcontext logView="true">,
11: simple page views without information about the previous page,
12: transitions between one page and another.

If you have configured a PageDataExtractor, you can expect some type 11 events for the first events in each session and many events of type 12. Otherwise, page views should be reported as many type 11 events.

If you use the Analytics taglib to create links, you should receive many type 6 events.

Analyze the Processing of Page Views

This procedure allows you to follow a page view through the system, determining where it might get lost. It assumes that page views are counted during rendering or by means of tracking images. This section does not apply when processing Apache logs.

Make sure that no pages are requested from the delivery CAEs by somebody other than you.
Run

cm dataaggregator -u admin shutdown

on the command line. The Data Aggregator should shut down after a few minutes without errors in the file var/log/workflowserver.log.

Generate a page view event by retrieving a page from the delivery CAE. If you use In-Site Analytics with JavaScript callbacks, you should click on a tracked link to bring up the page.
Wait a little, allowing the delays workflow.server.managers.aggregator.minimum.age and workflow.server.managers.aggregator.hint.delay from the file workflowserver.properties to pass, so that the page view events may be aggregated. Normally, a minute should suffice.
Run

cm dataaggregator -u admin once

and check the server log for errors. Verify that the Data Aggregator has completed its run by means of

cm dataaggregator -u admin status

until the Data Aggregator is down.



Verify that the log data has indeed been written to disk by opening the single file jakarta-tomcat/analyticslog/complete/report-*, where * is a string that encodes the logged time interval. Note that another directory might be used if so configured in the file tracking.properties.

The file contains one line per event with fields that are separated by tabs.


One line should start with an 11 or a 12. In the case of an 11, it should contain the object id, view, locale, and site for the rendered page. In the case of a 12, a PageDataExtractor has been configured and it was able to compute the predecessor page for the page view event. The log line should identify both the source page and the target page. If you designate a linked object in the <analytics:pagecontext> tag, that page should be represented in the log data, too.

If there isn't such an event, check whether either the Analytics taglib or the tracking interceptor are properly configured. In section you can find a description of both approaches.
Check the Tomcat log for error or warning messages.


One line should start with a 6, if JavaScript callbacks are used. The log line should identify both the source page and the target page.

If there isn't such an event, check whether the analytics taglib is properly used. You need at least the tags <analytics:head>, <analytics:pagecontext>, and either <analytics:link> or <analytics:linkattributes>.
Check whether the JavaScript onClick handler was properly rendered in the visited page. You might want to activate a JavaScript debugger for further debugging.
Check the Tomcat log for error or warning messages.
The sites of the rendered objects must be computed correctly. Because the site of an object cannot change late, you might have to restart with a fresh database after you change the computation algorithm. If that is not possible, you have to correct the already stored dimension data.
Execute some SQL statement to ensure that the data has reached the Analytics Database. A log line starting with a 11 should appear as a result of

SELECT * FROM StagingPageViews

whereas  a log line starting with a 12 should appear as a result of

SELECT * FROM StagingTransitions

and a log line starting with a 6 should appear as a result of

SELECT * FROM StagingTransitionHints

where the latter two also indicate a source page.

Execute

SELECT exactTime FROM ConsolidatedBefore

to retrieve a time value that should be later than your request of the tracked page.

The content of the staging tables should be consolidated into the fact table. Execute

SELECT * FROM PageViews WHERE eventTime =
  (SELECT MAX(eventTime) FROM PageViews)

to get the most recent event, which should be your test event. You can use the table PageDimension to translate the internal IDs to readable IDs.

SELECT * FROM PageDimension WHERE id = ...

inserting the page ID as appropriate. Using Oracle's outer join syntax, a combined query would look like

SELECT eventTime,
  pd1.pageObjectid AS sourceObject,
  pd1.pageView AS sourceView,
  pd1.pageLocale AS sourceLocale,
  pd2.pageObjectid AS targetObject,
  pd2.pageView AS targetView,
  pd2.pageLocale AS targetLocale
FROM PageViews, pageDimension pd1, pageDimension pd2
WHERE sourceId = pd1.id (+) AND pageId = pd2.id

to show all consolidated page views with readable IDs.

Analyzing the Object Analyzer

This procedure allows you to determine whether the Object Analyzer is running correctly.

Make sure that the Data Aggregator is not running. Otherwise, invalid temporary states might be persisted during the following steps.
Execute the SQL statement

DELETE FROM CurrentObjectState

to get rid of historic data that might obscure the present situation.

In the file config/objectanalyzer/proactivenegine.properties set proactiveengine.clear=true.
Start or restart the Object Analyzer.
Check the objectanalyzer.log for messages of the following form:

Statistics: QueueWorker[batches=7,
  batch duration=999|9999|99999,
  batch size=9|99|999,
  batch weight=9|99|999,
  jobs=999, job duration=9|99|999],
Queue[capacity=1000,
  current size=0,
  size=9|9|99,
  wait duration=9|99|999]

Such messages should appear regularly until the content is completely analyzed. At that point, the messages should stop abruptly.

Check the log for error messages.
Execute the SQL command

SELECT COUNT(*) FROM CurrentObjectState

and verify whether the result is equal to the number of resources in your repository (assuming you have not reconfigured the Proactive Engine triggers to limit the extend of the analysis).

Obtain the id of an example content that should be analyzed, e.g., 42. Execute the command

SELECT site,
  ObjectTypeDimension.name as typeName,
  CategoryDimension.fullPath AS category,
  isDeleted, isPublished, lastChange,
  displayName
FROM CurrentObjectState, CategoryDimension, ObjectTypeDimension 
WHERE CurrentObjectState.objectid='contentbean:42'
  AND CurrentObjectState.category = CategoryDimension.id
  AND CurrentObjectState.objectType = ObjectTypeDimension.id

to retrieve information about the content. In particular, check whether the site, the type, and the category are correctly computed. Repeat as needed with other content. If you correct the configured algorithms, make sure to regenerate the data by rerunning the Object Analyzer.

Using a DB tool, set the dates stored in the tables LastSnapshot and PermanentlyAggregatedBefore to one day before now.
Reset the property proactiveengine.clear to false and restart the Data Aggregator.
The Data Aggregator should now make a last snapshot of the current object state and aggregate the associate statistics. Because the statistics for an entire day are regenerated, this will take its time.
When the Data Aggregator has finished its first iteration, execute

SELECT COUNT(*) FROM ObjectStateSnapshot
WHERE logicalSnapshotTime = 
  (SELECT MAX(logicalSnapshotTime) FROM ObjectStateSnapshot)

to make sure that all content has made it into the snapshot.

Open the Analytics Dashboard to inspect the repository report. Check whether the distribution across categories and types looks plausible.