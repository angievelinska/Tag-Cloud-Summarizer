

The script parameter identifies an external shell script that is called when the importer determines that new files must be processed. The script is called and fetches the logs in a deployment specific way into the directory specified by the directory parameter. The script may fetch any number of log files into the given directory. It is guaranteed that the directory is empty before the script is invoked. The script may also move or remove the files in the archive directory.

The encoding parameter specifies the character encoding in which the log files are parsed. Only character encodings that encode line ends as bytes 10 or 13 are permitted. All common 8-bit encodings and UTF-8 fall into this category.

The advantage of configuring the properties in the Spring bean definition is that all definitions are in one place. The advantage of retrieving the properties from the file workflowserver.properties is that the properties are dynamically reloaded even while the Data Aggregator is running.

The property iterationStartVariable should almost always be set to iterationStart. The property importEndVariable should be set to customImportEnd, if the imported data relates to page views, and to customAdditionalImportEnd otherwise.

The property importerId must be unique for every importer that you deploy. This identifier is used when storing the state of the importer persistently in the database. Two importer mixing their state would reliably result in inconsistent data.

A number of implementations of ImporterStrategy are already delivered with CoreMedia CMS. You can find them in the package com.coremedia.analytics.wf.plugin. In the file config/dataaggregator/spring/dataaggregator-importers-example.xml you can find examples for all strategies presented here.

AccessLogImporterStrategy

This class is a generic importer for line-based log files that describe page view events. It assumes that the lines can be parsed by means of a regular expression as implemented by the standard Java class java.util.regex.Pattern. The regular expression must contain so-called capturing groups, that is subexpressions that are delimited by parentheses. The importer can then be instructed which aspect of a request (the requested URI, the date, the browser and so on) is to be found in which group. Groups are numbered starting from 1. A typical definition for this importer strategy might look like:

<bean class="com.coremedia.analytics.wf.plugin.
AccessLogImporterStrategy">
  <property name="linePattern"
   value="\[([^\]]*)\] ([^ ]*) &quot;([^&quot;]*)&quot; *"/>
  <property name="dateGroup" value="1"/>
  <property name="sessionGroup" value="2"/>
  <property name="ipGroup" value="2"/>
  <property name="uriGroup" value="3"/>
  <property name="rawPageDataExtractor">
    <bean class="MY_PACKAGE.MY_RAW_PAGE_DATA_EXTRACTOR"/>
  </property>
</bean>

Only the content of the property strategy of the ChunkingImporterAction is shown here. Please see the previous section for details on how to set up the other properties. This definition parses lines like:

[01/Jan/2000:01:01:01 +0100] 127.0.0.1 "/app/servlet/content/42"

The pattern defines three capturing groups containing the bracket-delimited date, the requestor's IP address and the request URI path, respectively. The IP address is reused as a session identifier, which is a plausible technique in the absense of a real session identifier.

Your log file format will likely be different, but you can adapt the line pattern as needed. The JavaDoc of the class AccessLogImporterStrategy gives hints on additional groups that can be defined and on additional strategies that can be set.

Before the given XML snippet can be used, you must create an implementation of the interface RawPageDataExtractor. An implementation must provide the method

RawPageData getRawPageData(URI uri)

whose return object encapsulates string identifiers for object, view, locale, and site of the viewed page. Often view, locale, and site will be constant, but the object identifier is always variable. For content beans, the object identifier is the numeric content id prefixed with "contentbean:".

The method should return null, if the URI could not be parsed and also if it denotes an object for which accesses are not supposed to be tracked, for example, an image or a JavaScript file.

Additional properties are defined in AccessLogImporterStrategy for parsing the time field. Especially, it is possible to set the format string of a SimpleDateFormat and the locale used for parsing.

IvwImporterStrategy

The IVW (Informationsgemeinschaft zur Feststellung der Verbreitung von Werbeträgern e.V.) is an independent German provider of usage statistics for various media. In particular, a standardized tracking plattform can produce log files that reflect the accesses to a web site.

CoreMedia Analytics can import IVW log files using the IvwImporterStrategy which can be plugged into a ChunkingImportAction. CoreMedia Analytics does not include means to generate IVW image elements at the moment. Therefore no specific format of the requested image URIs is expected. Client code is required to parse the reported URIs, similar to the AccessLogImporterStrategy described above.

The bean definition looks like:

<bean
 class="com.coremedia.analytics.wf.plugin.IvwImporterStrategy">
  <property name="rawRequestDataExtractor">
    <bean class="MY_PACKAGE.MY_RAW_REQUEST_DATA_EXTRACTOR"/>
  </property>
  <property name="robotProvider">
    <bean
     class="com.coremedia.analytics.plugin.DefaultRobotProvider">
      <property name="robotsDbLocation"
       value="config/dataaggregator/analytics-robots.db"/>
      <property name="providedRobotsCSV" value="*"/>
      <property name="providedWildcardsCSV" value="*"/>
      <property name="providedBrowsersCSV" value="*"/>
    </bean>
  </property>
</bean>

The line pattern and the group numbers are already preconfigured. Because IVW logs contain information about the browser that retrieves a tracking image, it is possible to filter robots and spiders based on this information. To this end, a robot provider is configured that reads the file analytics-robots.db as installed with the Data Aggregator.

For the extractor, you must implement the interface RawRequestDataExtractor, preferably by subclassing IvwRawRequestDataExtractorBase. When subclassing IvwRawRequestDataExtractorBase, you must implement the method

RawPageData getPageData(URI uri)

as described for the RawPageDataExtractor in the previous section on the AccessLogImporterStrategy. Additionally, you may overwrite the method


RawPageData getSourcePageData(URI referrer)

for identifying the referrer of the current page. The argument of this method is the referrer URI as passed through the r attribute of the original request. This method is only invoked when a referrer could be detected. The result is again a RawPageData object as in the previous method.

CommonLogImporterStrategy

Another specialized importer strategy derived from the AccessLogImporterStrategy is the CommonLogImporterStrategy, which parses the Apache common log format. The line pattern and the available groups are preconfigured by the strategy, you must only provide a RawPageDataExtractor for parsing the URI.

<bean class=
"com.coremedia.analytics.wf.plugin.CommonLogImporterStrategy">
  <property name="rawPageDataExtractor">
    <bean class="MY_PACKAGE.MY_RAW_PAGE_DATA_EXTRACTOR"/>
  </property>
</bean>

CombinedLogImporterStrategy

The Apache combined log format also includes information about the referring page and the browser. The CombinedLogImporterStrategy can use this information to compute the source page and to detect robot accesses.

<bean class=
"com.coremedia.analytics.wf.plugin.CombinedLogImporterStrategy">
  <property name="rawPageDataExtractor">
    <bean class="MY_PACKAGE.MY_RAW_PAGE_DATA_EXTRACTOR"/>
  </property>
  <property name="referrerRawPageDataExtractor">
    <bean class="MY_PACKAGE.MY_REFERRER_RAW_PAGE_DATA_EXTRACTOR"/>
  </property>
  <property name="robotProvider">
    <bean class=
     "com.coremedia.analytics.plugin.DefaultRobotProvider">
      <property name="robotsDbLocation"
       value="config/dataaggregator/analytics-robots.db"/>
      <property name="providedRobotsCSV" value="*"/>
      <property name="providedWildcardsCSV" value="*"/>
      <property name="providedBrowsersCSV" value="*"/>
    </bean>
  </property>
</bean>

To make full use of the combined log format, you have to configure two RawPageDataExtractor objects and a RobotProvider. For the robot provider it is possible to use the default implementation, but the extractors must be developed specifically for your project.